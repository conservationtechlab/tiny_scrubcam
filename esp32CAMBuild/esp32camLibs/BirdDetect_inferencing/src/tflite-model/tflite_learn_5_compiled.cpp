/*
 * Copyright (c) 2024 EdgeImpulse Inc.
 *
 * Generated by Edge Impulse and licensed under the applicable Edge Impulse
 * Terms of Service. Community and Professional Terms of Service
 * (https://docs.edgeimpulse.com/page/terms-of-service) or Enterprise Terms of
 * Service (https://docs.edgeimpulse.com/page/enterprise-terms-of-service),
 * according to your product plan subscription (the “License”).
 *
 * This software, documentation and other associated files (collectively referred
 * to as the “Software”) is a single SDK variation generated by the Edge Impulse
 * platform and requires an active paid Edge Impulse subscription to use this
 * Software for any purpose.
 *
 * You may NOT use this Software unless you have an active Edge Impulse subscription
 * that meets the eligibility requirements for the applicable License, subject to
 * your full and continued compliance with the terms and conditions of the License,
 * including without limitation any usage restrictions under the applicable License.
 *
 * If you do not have an active Edge Impulse product plan subscription, or if use
 * of this Software exceeds the usage limitations of your Edge Impulse product plan
 * subscription, you are not permitted to use this Software and must immediately
 * delete and erase all copies of this Software within your control or possession.
 * Edge Impulse reserves all rights and remedies available to enforce its rights.
 *
 * Unless required by applicable law or agreed to in writing, the Software is
 * distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
 * either express or implied. See the License for the specific language governing
 * permissions, disclaimers and limitations under the License.
 */
// Generated on: 28.06.2024 20:15:46

#include <stdio.h>
#include <stdlib.h>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#if defined __GNUC__
#define ALIGN(X) __attribute__((aligned(X)))
#elif defined _MSC_VER
#define ALIGN(X) __declspec(align(X))
#elif defined __TASKING__
#define ALIGN(X) __align(X)
#elif defined __ICCARM__
#define ALIGN(x) __attribute__((aligned(x)))
#endif

#ifndef EI_MAX_SCRATCH_BUFFER_COUNT
#ifndef CONFIG_IDF_TARGET_ESP32S3
#define EI_MAX_SCRATCH_BUFFER_COUNT 4
#else
#define EI_MAX_SCRATCH_BUFFER_COUNT 8
#endif // CONFIG_IDF_TARGET_ESP32S3
#endif // EI_MAX_SCRATCH_BUFFER_COUNT

#ifndef EI_MAX_OVERFLOW_BUFFER_COUNT
#define EI_MAX_OVERFLOW_BUFFER_COUNT 10
#endif // EI_MAX_OVERFLOW_BUFFER_COUNT

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX) || defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
constexpr int kTensorArenaSize = 15392;
#else
constexpr int kTensorArenaSize = 14368;
#endif

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};

enum used_operators_e {
  OP_RESHAPE, OP_CONV_2D, OP_MAX_POOL_2D, OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};

struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};

typedef struct {
  TfLiteTensor tensor;
  int16_t index;
} TfLiteTensorWithIndex;

typedef struct {
  TfLiteEvalTensor tensor;
  int16_t index;
} TfLiteEvalTensorWithIndex;

TfLiteContext ctx{};
static const int MAX_TFL_TENSOR_COUNT = 4;
static TfLiteTensorWithIndex tflTensors[MAX_TFL_TENSOR_COUNT];
static const int MAX_TFL_EVAL_COUNT = 4;
static TfLiteEvalTensorWithIndex tflEvalTensors[MAX_TFL_EVAL_COUNT];
TfLiteRegistration registrations[OP_LAST];

namespace g0 {
const TfArray<2, int> tensor_dimension0 = { 2, { 1,6435 } };
const TfArray<1, float> quant0_scale = { 1, { 0.009543311782181263, } };
const TfArray<1, int> quant0_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const ALIGN(16) int32_t tensor_data1[4] = { 1, 1, 99, 65, };
const TfArray<1, int> tensor_dimension1 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data2[4] = { 1, 99, 1, 8, };
const TfArray<1, int> tensor_dimension2 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data3[4] = { 1, 1, 50, 8, };
const TfArray<1, int> tensor_dimension3 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data4[4] = { 1, 50, 1, 16, };
const TfArray<1, int> tensor_dimension4 = { 1, { 4 } };
const ALIGN(8) int32_t tensor_data5[2] = { -1, 400, };
const TfArray<1, int> tensor_dimension5 = { 1, { 2 } };
const ALIGN(8) int32_t tensor_data6[2] = { 138889, -138889, };
const TfArray<1, int> tensor_dimension6 = { 1, { 2 } };
const TfArray<1, float> quant6_scale = { 1, { 2.0072150164196501e-06, } };
const TfArray<1, int> quant6_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant6 = { (TfLiteFloatArray*)&quant6_scale, (TfLiteIntArray*)&quant6_zero, 0 };
const ALIGN(16) int8_t tensor_data7[2*400] = { 
  27, -2, 35, 72, 28, 5, -10, -38, 6, 40, -33, -26, -45, 28, 27, 31, 79, 59, 26, 23, 14, 48, 5, 26, -13, 10, 13, 17, 42, -7, -17, 18, 0, 53, 26, -8, -42, -48, 6, 31, 18, 49, 9, 33, 11, 32, 0, -17, 15, -19, 5, -22, 24, -19, 24, -6, -44, -34, 52, 17, 4, -20, -7, -4, 15, 59, -2, 73, -33, 51, -9, 28, 16, 5, -19, -25, 7, -3, 5, -7, 17, 16, -34, 25, -2, 3, 6, 30, 28, -10, 39, 13, 37, -38, -31, 0, 31, 53, 24, 34, 0, 51, -17, -1, 13, 12, -3, 25, -38, -36, 25, -45, -23, 43, 8, 26, 6, 11, -27, -43, 3, -20, 7, 45, 75, -7, 31, -36, 41, 43, 13, 29, -40, -17, 9, -6, -26, 28, 44, 15, 71, 30, -13, 10, 10, -16, 3, 10, 0, 75, -24, -7, -14, -6, 27, -13, 2, 25, -27, 11, -43, 55, 7, 26, -28, -9, 21, 39, 23, -26, 36, 5, 69, 53, 46, -32, 44, -14, 76, 46, 20, 63, 31, 19, 13, -35, 21, -29, 17, 3, -36, -37, 30, 16, 27, 12, -4, -1, 64, 25, -4, 4, 14, -30, 57, -33, -9, 4, -30, -5, 25, 38, -39, 42, 2, 8, -3, -3, 46, -18, 62, 34, 36, -2, 21, 73, 49, 64, -32, 10, 10, 4, 26, 11, 53, -26, -46, 50, 6, 34, 27, 12, 31, 31, 6, 50, -6, -17, -2, 15, 47, -17, 25, 1, 5, -7, 16, 48, 38, 24, -44, 94, -24, -6, -15, 32, 51, 45, 39, 22, 46, -21, 53, 1, 23, -2, -6, 3, 18, 2, 4, -34, -48, 42, 40, 10, 14, 27, 48, 55, 1, 8, 12, 8, 30, 51, -12, 17, 88, 48, 5, 12, -25, 15, 12, 13, 56, 27, 8, 27, -10, -12, 6, -22, 18, -13, 46, 10, 41, -38, -13, -33, -15, -4, 25, 38, 49, 6, -13, 17, -4, 52, 31, -15, -4, 58, -40, 23, 23, 50, 5, 22, 26, -46, 1, 19, 9, -17, 72, 19, 1, -18, 47, 62, -1, -10, -31, 4, -18, -24, 10, 2, 45, -33, -42, 47, 47, 0, -5, 14, 5, 81, -22, 63, -30, -22, 23, 51, 55, 4, 16, -40, 5, -56, 16, -4, 6, -6, 20, 47, -21, 23, -26, 12, 18, 36, -4, 16, 27, 39, 
  24, -29, -17, -43, -19, -33, -47, 20, -36, 4, -38, -29, 5, 44, -24, -21, -51, -71, 0, -92, 40, -40, 2, 10, 21, -50, 18, -35, -27, 61, 0, 60, 15, -5, 4, -45, 18, -33, 35, 38, -37, 20, -52, -37, -35, 14, -40, 3, 23, -9, 12, -45, -7, 12, 37, -33, 22, -39, 11, 16, -21, -9, -49, -12, -4, -47, 4, -66, 16, -38, -34, -35, 1, 2, -20, -24, -45, -5, 0, -7, -41, -31, 13, -20, -2, -36, 28, -32, -42, 17, -18, 4, -47, 10, -32, 9, 12, -10, 35, -39, 51, -41, 21, 28, -40, 29, -45, 6, -5, 16, -31, 12, 15, -2, -24, 17, 51, -21, 28, -38, -36, -48, -3, -19, -33, -41, 33, -12, -63, -24, -48, -1, 46, 55, 33, -24, -21, -17, -50, 21, -20, -23, -30, 11, -47, -25, -24, 37, 20, -12, -32, 43, 26, -44, 5, -6, 5, -12, -14, -54, 6, -65, -20, -6, -5, -26, 14, 30, -44, 34, -88, 21, -65, -65, -7, 14, 11, 5, -19, -22, 1, -60, -42, -34, -38, -39, -39, -9, -29, 13, -30, -42, -31, -21, 4, -66, 49, -18, -50, -42, -14, -24, 9, -23, -51, -34, -21, -4, -4, 23, 6, 23, -6, -14, -37, -19, -36, 23, -64, 33, -12, 15, -25, 2, -13, -33, -32, -127, 10, -70, 39, -26, -4, -17, -50, -53, 41, -33, -42, -15, 18, -17, 10, -80, 53, -30, 25, 10, 6, 28, -49, -15, -57, 28, -30, -45, -10, -18, 11, -39, -18, -34, -16, 21, 13, -19, -111, -4, 14, 7, -28, -41, -36, 11, 1, 25, 15, 0, -25, 14, -10, 16, -16, -9, -17, -3, -11, 33, -25, 25, -37, -42, 32, -31, 37, -2, 13, -21, -12, 26, -33, 46, 18, 19, -20, 8, -31, -66, 2, 13, 22, -25, 20, -50, -64, -50, 40, -40, -5, -17, 29, -52, 40, -41, 5, -17, -28, -15, -10, -3, -7, -24, 9, 17, 18, -38, -32, -27, 3, -46, 50, -11, -4, 2, -10, 28, -45, -37, 7, 47, -34, 15, -1, 6, 36, 14, -3, -14, -3, 7, -18, 27, 14, 20, -5, -16, -10, -22, 6, -14, 37, -87, -15, -33, 35, 31, 38, 15, 22, 29, -57, 0, -10, 32, 17, -35, -12, -6, 36, -52, -53, -26, 19, -7, -50, 14, -24, -7, 20, -41, 
};
const TfArray<2, int> tensor_dimension7 = { 2, { 2,400 } };
const TfArray<1, float> quant7_scale = { 1, { 0.0027253185398876667, } };
const TfArray<1, int> quant7_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant7 = { (TfLiteFloatArray*)&quant7_scale, (TfLiteIntArray*)&quant7_zero, 0 };
const ALIGN(16) int32_t tensor_data8[16] = { 90627, 86651, 51830, 126136, -97348, 125217, -16132, -9312, 48720, -12026, 117202, -16240, 115334, -8082, 79226, 14230, };
const TfArray<1, int> tensor_dimension8 = { 1, { 16 } };
const TfArray<16, float> quant8_scale = { 16, { 1.367781237604504e-06, 1.1491022178233834e-06, 1.2521934422693448e-06, 1.1246621625105035e-06, 1.2678755183515023e-06, 1.4045792795513989e-06, 1.2582167983055115e-06, 1.3234929383543204e-06, 1.1239300192755763e-06, 1.2565900533445529e-06, 1.068723122443771e-06, 1.4206949572326266e-06, 1.4145829254630371e-06, 1.281261120311683e-06, 1.4037585742698866e-06, 1.2480782061174978e-06, } };
const TfArray<16, int> quant8_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const ALIGN(16) int8_t tensor_data9[16*1*3*8] = { 
  /* [0][0][][] */ 21,49,79,95,-38,-38,2,40, -25,26,-21,-21,-84,5,92,-127, 28,60,4,54,-101,-63,74,7, 
  /* [1][0][][] */ -91,113,-9,114,-8,-115,-12,45, -100,-30,-33,22,104,127,82,122, 108,22,49,-123,-73,-101,-4,-17, 
  /* [2][0][][] */ -33,47,-58,6,13,-71,36,51, 124,10,71,94,66,-127,-13,114, -104,59,38,-58,-40,5,127,-15, 
  /* [3][0][][] */ 74,-90,57,-37,111,-26,-101,91, 34,-127,-47,127,5,-59,-60,57, -113,5,-48,-42,67,-32,103,82, 
  /* [4][0][][] */ -75,-76,-92,-83,-123,-127,26,32, -104,-38,-79,-90,-39,50,48,-13, 48,86,53,-78,-107,86,-41,40, 
  /* [5][0][][] */ -89,69,33,91,-20,-118,-48,127, -104,57,-59,-32,85,84,-76,-46, -70,117,37,64,6,12,-87,61, 
  /* [6][0][][] */ 105,-3,47,66,-119,-41,14,10, 42,-94,50,-127,-37,-24,36,62, -52,-124,-81,77,-22,17,-98,-83, 
  /* [7][0][][] */ -22,101,-10,-112,-104,115,114,39, 54,97,64,127,83,81,37,84, 2,3,-104,-2,111,32,124,49, 
  /* [8][0][][] */ 62,-122,72,84,26,-67,80,65, -75,-89,-127,76,115,-59,-123,123, -47,-72,49,65,22,42,-11,-41, 
  /* [9][0][][] */ 19,-79,26,84,-52,56,88,58, -63,-51,-56,-91,4,38,-38,34, -37,-78,-89,100,-36,29,-60,127, 
  /* [10][0][][] */ -92,-79,-37,61,36,-50,116,-45, -118,-127,9,-5,-68,-113,-83,59, -72,-10,-29,94,-105,84,-12,127, 
  /* [11][0][][] */ -127,47,-79,89,78,5,-50,-86, -69,-68,7,1,112,-127,7,29, -45,-12,-106,62,-98,-116,-87,-47, 
  /* [12][0][][] */ -95,55,-72,127,-34,-11,116,-8, 54,-18,-74,-36,-101,67,-97,-51, 70,61,70,40,51,-103,-81,48, 
  /* [13][0][][] */ 6,-18,-64,-42,-124,69,-46,-43, 70,56,-61,19,-127,-119,-44,-113, -66,21,89,10,90,-107,-89,63, 
  /* [14][0][][] */ 56,13,56,-23,-26,56,21,-61, -22,97,73,38,-11,-12,37,-68, 86,-115,-7,127,20,-104,11,-84, 
  /* [15][0][][] */ 75,77,-24,-49,12,-70,-45,63, -16,-21,27,-20,13,-98,-15,60, -89,-103,26,-73,-127,-29,48,54, 
};
const TfArray<4, int> tensor_dimension9 = { 4, { 16,1,3,8 } };
const TfArray<16, float> quant9_scale = { 16, { 0.002365997526794672, 0.001987725030630827, 0.0021660530474036932, 0.0019454485736787319, 0.0021931799128651619, 0.0024296510964632034, 0.0021764722187072039, 0.0022893873974680901, 0.0019441819749772549, 0.0021736582275480032, 0.0018486847402527928, 0.0024575281422585249, 0.0024469555355608463, 0.0022163344547152519, 0.0024282315280288458, 0.0021589344833046198, } };
const TfArray<16, int> quant9_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&quant9_zero, 0 };
const ALIGN(16) int32_t tensor_data10[8] = { -1461, -1211, 4300, -2092, 0, -1697, -935, -2047, };
const TfArray<1, int> tensor_dimension10 = { 1, { 8 } };
const TfArray<8, float> quant10_scale = { 8, { 1.3720656170335133e-05, 1.3337144991965033e-05, 1.455576148146065e-05, 1.4475065654551145e-05, 1.2330317076703068e-05, 1.4404894500330556e-05, 1.3901502825319767e-05, 1.4625749827246182e-05, } };
const TfArray<8, int> quant10_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const ALIGN(16) int8_t tensor_data11[8*1*3*65] = { 
  /* [0][0][][] */ -11,48,-12,8,-125,-38,53,-66,-85,-52,18,-114,78,-100,-112,20,-27,-52,-40,-124,25,-22,30,54,41,-19,-6,-115,7,-125,-116,51,11,-66,45,-39,-1,-56,42,65,12,28,-108,58,-54,-73,97,30,-43,-48,79,87,-113,86,47,76,84,24,-37,53,-123,52,28,-14,-56, -68,67,-34,64,-68,-92,81,-99,-108,-43,12,50,28,-87,14,56,-30,76,-94,88,-120,-106,-47,-68,56,-87,-116,-3,-122,-93,-26,-91,-71,48,-87,35,-77,-18,18,0,-105,-123,-3,-58,-70,-111,-114,-29,-88,-59,-55,-54,74,55,52,-86,-74,-22,61,98,-35,-120,-6,67,-118, 24,95,-39,-55,4,-111,42,-32,92,-127,90,-2,-32,71,20,95,-30,58,50,35,24,58,-91,-107,-99,-4,83,-85,89,57,-34,-11,-98,48,12,-14,82,-20,96,26,78,53,-19,-46,61,12,-63,-110,14,-69,-85,4,-73,24,59,-40,-50,71,38,-127,63,-97,-68,-46,72, 
  /* [1][0][][] */ -115,-98,-22,88,-118,95,-100,105,-5,-6,-34,-68,85,-93,114,37,-107,-46,117,109,51,-64,40,26,28,-75,-100,-42,-42,31,16,-118,-42,54,31,71,-75,-84,-2,-84,91,-13,-82,33,-19,118,83,108,10,-44,-20,-24,63,-97,-93,96,23,-87,-59,-38,59,118,-63,-30,-118, -34,-7,-72,-30,88,-41,-17,-22,102,-4,-32,-65,-29,-25,-127,88,-98,-8,-84,-126,67,70,-2,-121,16,-105,67,100,-80,-21,18,-29,70,90,-48,-60,15,-123,32,45,101,-76,106,-44,-97,55,-62,23,-127,-70,74,64,-1,-90,54,-2,89,-101,63,59,-118,49,-66,-29,43, -9,-127,95,-61,-69,-29,-83,20,57,-59,-124,52,74,-27,68,85,-119,-38,-4,-33,-33,-117,24,-124,-53,-58,-93,45,-104,-103,-40,-11,-35,-13,79,76,-122,-26,81,80,52,-93,26,41,100,94,-85,79,-64,-34,58,90,64,-97,-34,5,-32,43,-87,-97,-48,97,-106,-29,-65, 
  /* [2][0][][] */ 57,78,-95,-23,-82,-81,58,66,-52,27,54,-80,59,-102,-56,76,71,-68,81,41,109,-3,-2,9,34,-83,-85,-105,-18,-119,-90,18,-105,49,92,-78,37,-96,-31,-56,21,-18,-10,-74,-7,-20,16,-82,63,-108,86,-113,-74,1,82,37,-123,-84,44,51,-14,61,-76,-40,-96, 91,-78,-8,-82,-80,-44,86,-90,34,-24,-49,-101,57,-97,-53,63,-80,-68,-10,70,-17,111,107,61,-74,-95,-34,25,35,14,52,-97,-98,94,-114,41,27,-94,11,73,-114,-10,-83,-16,49,17,-57,-19,-115,44,-78,-14,89,-78,-92,15,41,-110,-47,-72,30,-60,-21,62,18, -32,-53,39,67,-17,61,79,71,-12,-70,11,-74,-73,86,-29,11,22,-36,-44,-67,95,22,-41,4,36,-27,60,-84,-81,81,-46,10,36,10,78,4,-118,75,51,47,-52,29,-16,-81,34,-29,61,44,72,-89,-16,-48,59,28,-68,-42,-26,-127,39,26,-116,4,71,59,0, 
  /* [3][0][][] */ -109,-35,-24,-127,71,-77,76,-15,71,-122,-29,-103,-39,10,9,-31,87,12,23,-3,33,59,58,70,16,67,72,-108,83,21,32,49,54,21,30,26,-61,-22,-125,63,-103,-65,-23,-78,27,15,77,-78,80,43,-91,-45,-62,-90,70,-90,83,64,-23,27,45,12,-28,82,-20, -98,48,-90,9,-60,70,89,18,-37,-80,-68,-30,-96,79,-58,69,-16,71,-115,36,45,8,-11,-121,3,85,-96,-120,9,-121,0,7,-14,-58,75,-110,27,-92,10,-72,-19,73,8,83,-98,82,-78,-20,-32,-87,-25,4,-122,-112,-48,43,-114,-31,32,54,-91,-102,7,-50,-30, -41,13,-112,-3,72,6,79,30,-88,-82,-112,34,37,54,28,-64,-8,-93,-127,71,77,62,-104,-55,-87,82,-23,-99,-99,-67,-91,56,-102,9,24,41,50,-38,-65,-85,-89,-42,-98,88,49,41,-104,-124,-2,68,-79,-81,-52,23,73,3,66,-44,-1,57,-47,27,-111,41,4, 
  /* [4][0][][] */ 103,-58,-18,122,-82,20,1,104,-22,-9,-101,77,61,79,-30,106,-76,-81,-75,-92,-60,-103,-101,-20,-112,-37,-29,45,78,-40,-80,31,-82,-46,62,-88,-44,111,-54,46,73,16,91,-59,-63,-11,106,-61,26,-41,-14,59,-33,86,-73,-26,-80,22,52,-54,-41,64,80,81,-42, 91,9,-62,-12,97,-116,106,-113,-111,92,57,-54,39,-120,-1,112,-123,-104,-2,-76,-41,78,54,-36,-67,-40,102,91,107,-109,27,-108,-82,12,4,12,-15,-11,-66,-21,-111,-103,-38,-49,92,70,-127,104,37,-102,93,117,110,-16,-117,-25,-19,-90,38,-50,80,84,-118,-124,-16, -99,-127,-28,-80,-93,-35,-84,80,61,-121,80,-86,94,59,-26,110,-24,74,-47,-89,-109,-42,-51,-29,109,115,-97,-89,-51,8,6,20,-89,-121,58,-55,84,40,91,-48,-125,11,-16,-65,121,-110,-1,-107,-38,-26,87,58,-33,-102,109,52,35,-69,-114,67,-42,-50,58,-57,34, 
  /* [5][0][][] */ -47,11,-20,37,43,7,-71,3,-19,64,-50,87,7,52,-45,-2,-104,19,-13,79,-54,-28,89,-121,-26,-112,9,34,-86,95,-118,85,9,-39,65,7,-33,-69,73,-48,-110,-122,41,51,15,-47,-101,-77,-82,-72,-99,-97,-25,56,-60,-24,-18,-34,89,94,67,-59,40,60,-98, 10,-92,60,15,17,-69,-34,-97,31,-82,-40,15,82,-49,-100,66,-100,85,-23,9,7,-33,-52,15,89,56,32,-28,65,-76,27,70,-68,-3,-111,55,82,-79,26,-51,-94,71,58,8,-51,0,73,-48,-127,-90,-99,-23,-93,27,85,-21,91,-18,-103,35,78,17,-30,85,-80, 19,-97,-58,-119,42,31,82,-127,3,-99,21,2,69,-5,-111,46,40,-102,17,-68,11,-17,59,-75,-100,54,-36,-35,65,87,-47,54,-16,-44,40,-58,72,-125,-50,-16,77,3,-47,27,-49,82,-110,-80,53,-59,56,50,-25,-16,80,-127,32,70,-101,7,-32,-78,-80,-50,-100, 
  /* [6][0][][] */ 55,102,-15,26,-29,-40,-61,-80,-108,-110,-70,8,-59,-45,10,-37,-51,94,18,-11,-40,53,-10,37,-40,-4,108,18,34,-43,1,-97,54,-87,-80,44,-111,78,-65,-59,-45,-100,66,-1,-67,110,63,48,24,43,-53,94,-105,53,94,-50,-57,-88,88,89,-45,-106,-28,-20,-98, 113,-17,55,-36,-32,91,88,-88,76,-78,75,113,74,-89,-49,1,-52,-81,-24,-102,-88,-18,-37,99,89,-102,-90,-7,-88,-76,-91,89,-86,31,-38,-12,-113,58,-14,23,-9,-108,-19,-35,58,-56,-18,-21,78,-18,109,-42,-90,-107,26,-11,-110,-29,43,-104,-74,-23,-25,-70,-96, -120,16,-22,-28,-86,13,-104,-118,80,-97,-9,85,-1,-66,-90,46,77,-50,-35,65,-87,-11,-54,21,-74,62,-89,4,55,75,37,-1,51,-127,-73,-117,82,-81,24,-104,-102,-38,-54,14,85,4,-12,-127,-4,44,-50,81,77,-62,-67,13,79,-112,84,15,37,-64,44,-86,6, 
  /* [7][0][][] */ 59,-20,36,17,61,10,-99,44,-52,-72,73,-120,42,-115,-55,9,-33,84,-62,-34,-54,19,-110,-44,53,-43,-26,66,79,65,-58,-79,46,78,-21,-90,31,-43,29,-64,-55,-2,-71,-57,-109,-92,18,48,-17,9,68,-118,24,-43,-118,-77,-107,-59,-16,-104,-44,5,35,23,-17, -49,-67,44,33,-65,-121,-40,50,22,65,4,8,24,-42,-4,3,-58,-67,-63,-86,-59,-28,-6,-43,18,-39,-20,-122,7,4,53,8,53,37,-33,-39,42,45,57,-94,88,12,63,-36,40,17,56,-102,-53,-106,2,-116,-88,30,9,-83,-98,30,-29,-16,-93,25,-23,53,30, -40,56,-127,16,17,-54,23,-102,42,-75,-112,74,-124,-39,-109,51,-97,-32,-106,70,-92,-17,17,38,52,35,0,57,-49,18,37,-3,-116,44,-32,6,-3,-112,-46,-92,-69,-10,-117,-44,-83,-85,-112,-76,-16,51,-40,67,-96,-84,-35,-22,24,17,10,17,-60,-65,88,66,-125, 
};
const TfArray<4, int> tensor_dimension11 = { 4, { 8,1,3,65 } };
const TfArray<8, float> quant11_scale = { 8, { 0.0014377248007804155, 0.0013975384645164013, 0.0015252316370606422, 0.0015167759265750647, 0.0012920375447720289, 0.0015094230184331536, 0.001456674886867404, 0.0015325654530897737, } };
const TfArray<8, int> quant11_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&quant11_zero, 0 };
const TfArray<4, int> tensor_dimension12 = { 4, { 1,1,99,65 } };
const TfArray<1, float> quant12_scale = { 1, { 0.009543311782181263, } };
const TfArray<1, int> quant12_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&quant12_zero, 0 };
const TfArray<4, int> tensor_dimension13 = { 4, { 1,1,99,8 } };
const TfArray<1, float> quant13_scale = { 1, { 0.00057809916324913502, } };
const TfArray<1, int> quant13_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&quant13_zero, 0 };
const TfArray<4, int> tensor_dimension14 = { 4, { 1,99,1,8 } };
const TfArray<1, float> quant14_scale = { 1, { 0.00057809916324913502, } };
const TfArray<1, int> quant14_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&quant14_zero, 0 };
const TfArray<4, int> tensor_dimension15 = { 4, { 1,50,1,8 } };
const TfArray<1, float> quant15_scale = { 1, { 0.00057809916324913502, } };
const TfArray<1, int> quant15_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant15 = { (TfLiteFloatArray*)&quant15_scale, (TfLiteIntArray*)&quant15_zero, 0 };
const TfArray<4, int> tensor_dimension16 = { 4, { 1,1,50,8 } };
const TfArray<1, float> quant16_scale = { 1, { 0.00057809916324913502, } };
const TfArray<1, int> quant16_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant16 = { (TfLiteFloatArray*)&quant16_scale, (TfLiteIntArray*)&quant16_zero, 0 };
const TfArray<4, int> tensor_dimension17 = { 4, { 1,1,50,16 } };
const TfArray<1, float> quant17_scale = { 1, { 0.00073650653939694166, } };
const TfArray<1, int> quant17_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant17 = { (TfLiteFloatArray*)&quant17_scale, (TfLiteIntArray*)&quant17_zero, 0 };
const TfArray<4, int> tensor_dimension18 = { 4, { 1,50,1,16 } };
const TfArray<1, float> quant18_scale = { 1, { 0.00073650653939694166, } };
const TfArray<1, int> quant18_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant18 = { (TfLiteFloatArray*)&quant18_scale, (TfLiteIntArray*)&quant18_zero, 0 };
const TfArray<4, int> tensor_dimension19 = { 4, { 1,25,1,16 } };
const TfArray<1, float> quant19_scale = { 1, { 0.00073650653939694166, } };
const TfArray<1, int> quant19_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant19 = { (TfLiteFloatArray*)&quant19_scale, (TfLiteIntArray*)&quant19_zero, 0 };
const TfArray<2, int> tensor_dimension20 = { 2, { 1,400 } };
const TfArray<1, float> quant20_scale = { 1, { 0.00073650653939694166, } };
const TfArray<1, int> quant20_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant20 = { (TfLiteFloatArray*)&quant20_scale, (TfLiteIntArray*)&quant20_zero, 0 };
const TfArray<2, int> tensor_dimension21 = { 2, { 1,2 } };
const TfArray<1, float> quant21_scale = { 1, { 0.013466318137943745, } };
const TfArray<1, int> quant21_zero = { 1, { -1 } };
const TfLiteAffineQuantization quant21 = { (TfLiteFloatArray*)&quant21_scale, (TfLiteIntArray*)&quant21_zero, 0 };
const TfArray<2, int> tensor_dimension22 = { 2, { 1,2 } };
const TfArray<1, float> quant22_scale = { 1, { 0.00390625, } };
const TfArray<1, int> quant22_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant22 = { (TfLiteFloatArray*)&quant22_scale, (TfLiteIntArray*)&quant22_zero, 0 };
const TfLiteReshapeParams opdata0 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs0 = { 2, { 0,1 } };
const TfArray<1, int> outputs0 = { 1, { 12 } };
const TfLiteConvParams opdata1 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs1 = { 3, { 12,11,10 } };
const TfArray<1, int> outputs1 = { 1, { 13 } };
const TfLiteReshapeParams opdata2 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs2 = { 2, { 13,2 } };
const TfArray<1, int> outputs2 = { 1, { 14 } };
const TfLitePoolParams opdata3 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs3 = { 1, { 14 } };
const TfArray<1, int> outputs3 = { 1, { 15 } };
const TfLiteReshapeParams opdata4 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs4 = { 2, { 15,3 } };
const TfArray<1, int> outputs4 = { 1, { 16 } };
const TfLiteConvParams opdata5 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs5 = { 3, { 16,9,8 } };
const TfArray<1, int> outputs5 = { 1, { 17 } };
const TfLiteReshapeParams opdata6 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs6 = { 2, { 17,4 } };
const TfArray<1, int> outputs6 = { 1, { 18 } };
const TfLitePoolParams opdata7 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs7 = { 1, { 18 } };
const TfArray<1, int> outputs7 = { 1, { 19 } };
const TfLiteReshapeParams opdata8 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs8 = { 2, { 19,5 } };
const TfArray<1, int> outputs8 = { 1, { 20 } };
const TfLiteFullyConnectedParams opdata9 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs9 = { 3, { 20,7,6 } };
const TfArray<1, int> outputs9 = { 1, { 21 } };
const TfLiteSoftmaxParams opdata10 = { 1 };
const TfArray<1, int> inputs10 = { 1, { 21 } };
const TfArray<1, int> outputs10 = { 1, { 22 } };
};

TensorInfo_t tensorData[] = {
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 6448), (TfLiteIntArray*)&g0::tensor_dimension0, 6435, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant0))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data1, (TfLiteIntArray*)&g0::tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data2, (TfLiteIntArray*)&g0::tensor_dimension2, 16, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data3, (TfLiteIntArray*)&g0::tensor_dimension3, 16, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data4, (TfLiteIntArray*)&g0::tensor_dimension4, 16, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data5, (TfLiteIntArray*)&g0::tensor_dimension5, 8, {kTfLiteNoQuantization, nullptr}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data6, (TfLiteIntArray*)&g0::tensor_dimension6, 8, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant6))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data7, (TfLiteIntArray*)&g0::tensor_dimension7, 800, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant7))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data8, (TfLiteIntArray*)&g0::tensor_dimension8, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant8))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data9, (TfLiteIntArray*)&g0::tensor_dimension9, 384, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant9))}, },
{ kTfLiteMmapRo, kTfLiteInt32, (int32_t*)g0::tensor_data10, (TfLiteIntArray*)&g0::tensor_dimension10, 32, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant10))}, },
{ kTfLiteMmapRo, kTfLiteInt8, (int32_t*)g0::tensor_data11, (TfLiteIntArray*)&g0::tensor_dimension11, 1560, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant11))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension12, 6435, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant12))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 6448), (TfLiteIntArray*)&g0::tensor_dimension13, 792, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant13))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension14, 792, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant14))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 800), (TfLiteIntArray*)&g0::tensor_dimension15, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant15))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension16, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant16))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 800), (TfLiteIntArray*)&g0::tensor_dimension17, 800, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant17))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension18, 800, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant18))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 800), (TfLiteIntArray*)&g0::tensor_dimension19, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant19))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension20, 400, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant20))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 400), (TfLiteIntArray*)&g0::tensor_dimension21, 2, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant21))}, },
{ kTfLiteArenaRw, kTfLiteInt8, (int32_t*)(tensor_arena + 0), (TfLiteIntArray*)&g0::tensor_dimension22, 2, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&g0::quant22))}, },
};

#ifndef TF_LITE_STATIC_MEMORY
TfLiteNode tflNodes[11] = {
{ (TfLiteIntArray*)&g0::inputs0, (TfLiteIntArray*)&g0::outputs0, (TfLiteIntArray*)&g0::inputs0, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata0)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs1, (TfLiteIntArray*)&g0::outputs1, (TfLiteIntArray*)&g0::inputs1, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata1)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs2, (TfLiteIntArray*)&g0::outputs2, (TfLiteIntArray*)&g0::inputs2, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata2)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs3, (TfLiteIntArray*)&g0::outputs3, (TfLiteIntArray*)&g0::inputs3, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata3)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs4, (TfLiteIntArray*)&g0::outputs4, (TfLiteIntArray*)&g0::inputs4, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata4)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs5, (TfLiteIntArray*)&g0::outputs5, (TfLiteIntArray*)&g0::inputs5, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata5)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs6, (TfLiteIntArray*)&g0::outputs6, (TfLiteIntArray*)&g0::inputs6, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata6)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs7, (TfLiteIntArray*)&g0::outputs7, (TfLiteIntArray*)&g0::inputs7, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata7)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs8, (TfLiteIntArray*)&g0::outputs8, (TfLiteIntArray*)&g0::inputs8, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata8)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs9, (TfLiteIntArray*)&g0::outputs9, (TfLiteIntArray*)&g0::inputs9, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata9)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs10, (TfLiteIntArray*)&g0::outputs10, (TfLiteIntArray*)&g0::inputs10, nullptr, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata10)), nullptr, 0, },
};
#else
TfLiteNode tflNodes[11] = {
{ (TfLiteIntArray*)&g0::inputs0, (TfLiteIntArray*)&g0::outputs0, (TfLiteIntArray*)&g0::inputs0, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata0)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs1, (TfLiteIntArray*)&g0::outputs1, (TfLiteIntArray*)&g0::inputs1, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata1)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs2, (TfLiteIntArray*)&g0::outputs2, (TfLiteIntArray*)&g0::inputs2, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata2)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs3, (TfLiteIntArray*)&g0::outputs3, (TfLiteIntArray*)&g0::inputs3, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata3)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs4, (TfLiteIntArray*)&g0::outputs4, (TfLiteIntArray*)&g0::inputs4, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata4)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs5, (TfLiteIntArray*)&g0::outputs5, (TfLiteIntArray*)&g0::inputs5, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata5)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs6, (TfLiteIntArray*)&g0::outputs6, (TfLiteIntArray*)&g0::inputs6, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata6)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs7, (TfLiteIntArray*)&g0::outputs7, (TfLiteIntArray*)&g0::inputs7, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata7)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs8, (TfLiteIntArray*)&g0::outputs8, (TfLiteIntArray*)&g0::inputs8, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata8)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs9, (TfLiteIntArray*)&g0::outputs9, (TfLiteIntArray*)&g0::inputs9, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata9)), nullptr, 0, },
{ (TfLiteIntArray*)&g0::inputs10, (TfLiteIntArray*)&g0::outputs10, (TfLiteIntArray*)&g0::inputs10, nullptr, const_cast<void*>(static_cast<const void*>(&g0::opdata10)), nullptr, 0, },
};
#endif

used_operators_e used_ops[] =
{OP_RESHAPE, OP_CONV_2D, OP_RESHAPE, OP_MAX_POOL_2D, OP_RESHAPE, OP_CONV_2D, OP_RESHAPE, OP_MAX_POOL_2D, OP_RESHAPE, OP_FULLY_CONNECTED, OP_SOFTMAX, };


// Indices into tflTensors and tflNodes for subgraphs
const size_t tflTensors_subgraph_index[] = {0, 23, };
const size_t tflNodes_subgraph_index[] = {0, 11, };

// Input/output tensors
static const int in_tensor_indices[] = {
  0, 
};

static const int out_tensor_indices[] = {
  22, 
};


size_t current_subgraph_index = 0;

static void init_tflite_tensor(size_t i, TfLiteTensor *tensor) {
  tensor->type = tensorData[i].type;
  tensor->is_variable = false;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  tensor->allocation_type = tensorData[i].allocation_type;
#else
  tensor->allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
  tensor->bytes = tensorData[i].bytes;
  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  if(tensor->allocation_type == kTfLiteArenaRw){
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
      tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
  tensor->quantization = tensorData[i].quantization;
  if (tensor->quantization.type == kTfLiteAffineQuantization) {
    TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
    tensor->params.scale = quant->scale->data[0];
    tensor->params.zero_point = quant->zero_point->data[0];
  }

}

static void init_tflite_eval_tensor(int i, TfLiteEvalTensor *tensor) {

  tensor->type = tensorData[i].type;

  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  auto allocation_type = tensorData[i].allocation_type;
  if(allocation_type == kTfLiteArenaRw) {
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
    tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
}

static void* overflow_buffers[EI_MAX_OVERFLOW_BUFFER_COUNT];
static size_t overflow_buffers_ix = 0;
static void * AllocatePersistentBufferImpl(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  uint32_t align_bytes = (bytes % 16) ? 16 - (bytes % 16) : 0;

  if (current_location - (bytes + align_bytes) < tensor_boundary) {
    if (overflow_buffers_ix > EI_MAX_OVERFLOW_BUFFER_COUNT - 1) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d, does not fit in tensor arena and reached EI_MAX_OVERFLOW_BUFFER_COUNT\n",
        (int)bytes);
      return NULL;
    }

    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers[overflow_buffers_ix++] = ptr;
    return ptr;
  }

  current_location -= bytes;

  // align to the left aligned boundary of 16 bytes
  current_location -= 15; // for alignment
  current_location += 16 - ((uintptr_t)(current_location) & 15);

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}

typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;

static scratch_buffer_t scratch_buffers[EI_MAX_SCRATCH_BUFFER_COUNT];
static size_t scratch_buffers_ix = 0;

static TfLiteStatus RequestScratchBufferInArenaImpl(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  if (scratch_buffers_ix > EI_MAX_SCRATCH_BUFFER_COUNT - 1) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d, reached EI_MAX_SCRATCH_BUFFER_COUNT\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBufferImpl(ctx, b.bytes);
  if (!b.ptr) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffers[scratch_buffers_ix] = b;
  *buffer_idx = scratch_buffers_ix;

  scratch_buffers_ix++;

  return kTfLiteOk;
}

static void* GetScratchBufferImpl(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > (int)scratch_buffers_ix) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static const uint16_t TENSOR_IX_UNUSED = 0x7FFF;

static void ResetTensors() {
  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    tflTensors[ix].index = TENSOR_IX_UNUSED;
  }
  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    tflEvalTensors[ix].index = TENSOR_IX_UNUSED;
  }
}

static TfLiteTensor* GetTensorImpl(const struct TfLiteContext* context,
                               int tensor_idx) {

  tensor_idx = tflTensors_subgraph_index[current_subgraph_index] + tensor_idx;

  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    // already used? OK!
    if (tflTensors[ix].index == tensor_idx) {
      return &tflTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_tensor(tensor_idx, &tflTensors[ix].tensor);
      tflTensors[ix].index = tensor_idx;
      return &tflTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_TENSOR_COUNT (%d)\n", MAX_TFL_TENSOR_COUNT);
  return nullptr;
}

static TfLiteEvalTensor* GetEvalTensorImpl(const struct TfLiteContext* context,
                                       int tensor_idx) {

  tensor_idx = tflTensors_subgraph_index[current_subgraph_index] + tensor_idx;

  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    // already used? OK!
    if (tflEvalTensors[ix].index == tensor_idx) {
      return &tflEvalTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflEvalTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_eval_tensor(tensor_idx, &tflEvalTensors[ix].tensor);
      tflEvalTensors[ix].index = tensor_idx;
      return &tflEvalTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_EVAL_COUNT (%d)\n", (int)MAX_TFL_EVAL_COUNT);
  return nullptr;
}

class EonMicroContext : public MicroContext {
 public:
 
  EonMicroContext(): MicroContext(nullptr, nullptr, nullptr) { }

  void* AllocatePersistentBuffer(size_t bytes) {
    return AllocatePersistentBufferImpl(nullptr, bytes);
  }

  TfLiteStatus RequestScratchBufferInArena(size_t bytes,
                                           int* buffer_index) {
  return RequestScratchBufferInArenaImpl(nullptr, bytes, buffer_index);
  }

  void* GetScratchBuffer(int buffer_index) {
    return GetScratchBufferImpl(nullptr, buffer_index);
  }
 
  TfLiteTensor* AllocateTempTfLiteTensor(int tensor_index) {
    return GetTensorImpl(nullptr, tensor_index);
  }

  void DeallocateTempTfLiteTensor(TfLiteTensor* tensor) {
    return;
  }

  bool IsAllTempTfLiteTensorDeallocated() {
    return true;
  }

  TfLiteEvalTensor* GetEvalTensor(int tensor_index) {
    return GetEvalTensorImpl(nullptr, tensor_index);
  }

};


} // namespace

TfLiteStatus tflite_learn_5_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    ei_printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;

  EonMicroContext micro_context_;
  
  // Set microcontext as the context ptr
  ctx.impl_ = static_cast<void*>(&micro_context_);
  // Setup tflitecontext functions
  ctx.AllocatePersistentBuffer = &AllocatePersistentBufferImpl;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArenaImpl;
  ctx.GetScratchBuffer = &GetScratchBufferImpl;
  ctx.GetTensor = &GetTensorImpl;
  ctx.GetEvalTensor = &GetEvalTensorImpl;
  ctx.ReportError = &MicroContextReportOpError;

  ctx.tensors_size = 23;
  for (size_t i = 0; i < 23; ++i) {
    TfLiteTensor tensor;
    init_tflite_tensor(i, &tensor);
    if (tensor.allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tensor.data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }

  if (tensor_boundary > current_location /* end of arena size */) {
    ei_printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }

  registrations[OP_RESHAPE] = Register_RESHAPE();
  registrations[OP_CONV_2D] = Register_CONV_2D();
  registrations[OP_MAX_POOL_2D] = Register_MAX_POOL_2D();
  registrations[OP_FULLY_CONNECTED] = Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = Register_SOFTMAX();

  for (size_t g = 0; g < 1; ++g) {
    current_subgraph_index = g;
    for(size_t i = tflNodes_subgraph_index[g]; i < tflNodes_subgraph_index[g+1]; ++i) {
      if (registrations[used_ops[i]].init) {
        tflNodes[i].user_data = registrations[used_ops[i]].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
      }
    }
  }
  current_subgraph_index = 0;

  for(size_t g = 0; g < 1; ++g) {
    current_subgraph_index = g;
    for(size_t i = tflNodes_subgraph_index[g]; i < tflNodes_subgraph_index[g+1]; ++i) {
      if (registrations[used_ops[i]].prepare) {
        ResetTensors();
        TfLiteStatus status = registrations[used_ops[i]].prepare(&ctx, &tflNodes[i]);
        if (status != kTfLiteOk) {
          return status;
        }
      }
    }
  }
  current_subgraph_index = 0;

  return kTfLiteOk;
}

TfLiteStatus tflite_learn_5_input(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(in_tensor_indices[index], tensor);
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_5_output(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(out_tensor_indices[index], tensor);
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_5_invoke() {
  for (size_t i = 0; i < 11; ++i) {
    ResetTensors();

    TfLiteStatus status = registrations[used_ops[i]].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_5_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif

  // scratch buffers are allocated within the arena, so just reset the counter so memory can be reused
  scratch_buffers_ix = 0;

  // overflow buffers are on the heap, so free them first
  for (size_t ix = 0; ix < overflow_buffers_ix; ix++) {
    ei_free(overflow_buffers[ix]);
  }
  overflow_buffers_ix = 0;
  return kTfLiteOk;
}
